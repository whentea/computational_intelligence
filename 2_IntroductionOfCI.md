# Computational-Intelligence  

 
>>Nature has evolved over billions of years, providing a rich source of inspiration {2, Preface}

{Yang, 2014, Page 14}   
## Introduction  
CI is a branch of AI. In principle, CI consists of any science-supported approaches and technologies for analyzing, creating and developing intelligent system. Unlike AI that depends upon the knowledge derived from human expertise, however, CI mostly relies on the collection of numerical data and a set of nature-inspired computational paradigms. {1, 2}  
The major subject of CI is the study of unorthodox optimization technique.  
The aims are to utilize a finite commodity to archieve certain goals or objectives and to produce the maximum acceptability considering the initial goal (objective function).  
Traditionally, optimization problem were solved either using 3 ways like following diagram:  
<img src="https://github.com/whentea/afbeldingeen/blob/master/traditional.jpg" align="center" width="600">  

## Optimization : Core Principles and Technical Terms  
<img src="https://github.com/whentea/afbeldingeen/blob/master/core.jpg" align="center" width="600">  
Memory vs Memory-Less  
<img src="https://github.com/whentea/afbeldingeen/blob/master/memory.jpg" align="center" width="600">  
 
 
 
## Brief History of CI-Based Optimization Algorithms  
<img src="https://github.com/whentea/afbeldingeen/blob/master/brief.jpg" align="center" width="600">  

## Classification of CI-Based Optimization Algorithms  
<img src="https://github.com/whentea/afbeldingeen/blob/master/classification1.jpg" align="center" width="600">  
<img src="https://github.com/whentea/afbeldingeen/blob/master/classification2.jpg" align="center" width="600">  
<img src="https://github.com/whentea/afbeldingeen/blob/master/classification3.jpg" align="center" width="600">  

## No Free Lunch Theorem: The Reason behind New Algorithms  
## Conclusion  


  
Most convensional or classic algorithms are deterministric. Some deterministic optimization algorithms used the gradient information, so they are called gradient-based algorithms.  
It does not work well in some discontinuity in the object function.  
In this case, nongradient-based or gradient-free algorithms do not use any derivative, only the function values.  

The new paradigm is the stochastic algorithms. The recent trend tends to name all stochastic algorithms with randomization and local search.  
For the stochastic algorithms, in general there are two types: HEURISTIC and METAHEURISTIC.  
Two major components of any metaheuristic algorithms are INTENSIFICATION and DIVERSIFICATION, or EXPLOITATION and EXPLORATION.  
The good combination of these two major components will usually ensure that the global optimally is achievable.  

Metaheuristic algorithms can be classified in many ways. One way is to classify them as population-based (multiple agents or particles) or trajectory-based, an the other one is a single agent.  

>>The core principle of all CI-based optimization algorithms, which are better known as metaheuristic algorithms, is a way of trial and error to produce an acceptable solution to a complex problem in a reasonably practical time (Yang 2010) {1, Page 3}  
  
An optimization algorithm is an iterative procedure, starting from an initial guess {2, Page 24}.  


A considerable number of novel nature-based optimization algorithms {1, 9-151}:  
* Cat Swarm Optimization (CSO) Algorithm  
* League Championship Algorithm (LCA)  
* Anarchic Society Optimization (ASO) Algorithm  
* Cuckoo Optimization Algorithm (COA)  
* Teaching-Learning-Based Optimization (TLBO) Algorithm  
* Flower Pollination Algorithm (FPA)  
* Krill Herd Algorithm (KHA)  
* Grey Wolf Optimization (GWO) Algorithm  
* Shark Smell Optimization (SSO) Algorithm  
* Ant Lion Optimizer (ALO) Algorithm  
* Gradient Evolution (GE) Algorithm  
* Moth-Flame Optimization (MFO) Algorithm  
* Crow Search Algorithm (CSA)  
* Dragonfly Algorithm (DA)  


  
**Refer to:**  
[1] Omid Bozorg-Haddad (2018), Advanced Optimization by Nature-Inspired Algorithms (Studies Computational Intelligence), Springer.  
[2] Xin-She Yang (2014), Nature-Inspired Optimization Algorithms, Elsevier Inc.
